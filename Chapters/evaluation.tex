\chapter{Evaluation}\label{cha:eval}
Here we will present the evaluation of the model. The focus of the test will be on retrieving the optimal solution from the solvers. This is when the solver has reached a solution and ended the search, thereby concluding that the last reached conclusion was the optimal. Each solver was given a time limit of 4 hours to complete the search as it seemed long enough to have a high probability of retrieving a result from all the solver, but short enough to be manageable to test. But as can be seen in section \ref{sec:res}, this was not always the case. In the case where the solvers could produce a result in the given time frame the solvers where run 10 times and the average time was used. But the optimal solution is maybe not always the goal of the assembly or not feasible in any reasonable time. The case could be such that one has a certain amount of time at hand and want to get a good assembly in that amount of time. Therefore we will also present information for the solvers that did not end the search within the given time but produced solutions, some even the optimal.

Originally, the 1.6 version of MiniZinc was used. But during the making of the model version 2.0 was released. According to NICTA, the 2.0 version is a complete rewrite of the MiniZinc-to-FlatZinc comipiler but that the resulting FlatZinc file is compatile with 1.6 solvers, and therefore no changes should be required for the solvers \cite{mz2}. We therefore thought it could be of interest to compare how the 2.0 version performed compare to the 1.6 version. During the test phase of the thesis version 2.0.1 was released that should fix some bugs in 2.0 \cite{mz2_changelog}. Therefore, version 2.0.1 is used.

Apart from measuring the time, we also analysed the resulting FlatZinc file to see if we could see any correlation between the running time and the data run. The data extracted was the number of integer and boolean variables, the number of arrays, the number of constraints and the percentage of constraints that were reified. We measure the reifieds since even if we try to avoid direct reifieds in the MiniZinc code, the FlatZinc could still contain reified constraints depending on how it translates the MiniZinc code.

In order to see if the filtering we introduced made any difference, we also measure the different combinations of the filters and the absence of filters. Because of all the combinations of parameters we want to test, there will be 8 test cases for each solver.

What we want to achieve is to get the solver to reach the optimal solution and conclude that it is the optimal solution, that is what we mean when we say \emph{result}. And it should be noted that the result is only analysed in comparison to the handmade assembly, so it will not be tested on an actual physical robot.

\section{The Setup}
The computer used to run the solvers was equipped with an Intel i7 2.8GHz quad core CPU, 8GB DDR3 1333MHz memory and running Mageia 4.
\\\\
The versions of each of the solvers are presented in the table below.
\begin{table}[h]
\centering
\begin{tabular}{l|l}
Solver                    & Version \\ \hline
G12/FD                    & 1.6.0\\
JaCoP                     & 4.2 \\
Gecode                    & 4.3.2 \\
or-tools                  & Rev. 3782 \\
Opturion CPX              & 1.0.2 \\
\multirow{2}{*}{Chcoco 3} & Solver: 3.2.2 \\
                          & Parser: 3.2.0
\end{tabular}
\end{table}\\\\
Note that for Choco3, the solver and parser has different version numbers. This is because they are not distributed together and therefore have slightly different version numbers. It is possible to specify the number of cores used by the solver for Gecode, or-tools and Choco3. Hence, these three were given access to all 4 cores when running.

The versions of the solvers used are the latest as of December 2014.

\section{The results}\label{sec:res}
The time for the assembly reached by the solvers as the optimal was 512 time units. This is the time we will use as the optimal when we henceforth talk about which solvers reached the optimal but did not finish the search.

The results presented in the tables \ref{tab:res_g12} to \ref{tab:res_choco} are the runtimes of the solvers and the analysis of the FlatZinc files. The tests are grouped into 4 categories of runs; with predecessor filter and temporal filter, with only predecessor filter, with only temporal filter and with no filter at all. In each of these groups there are two groups, one for each version we tests, i.e. MiniZinc 1.6 and 2.0.1.

For the solvers that did not end their search in the 4 hour time limit but still produced results we present the number of solutions reached in the 4 hours, \emph{\# solutions}. When a value is marked with a asterisk(*) it means the solver also reached the optimal solution in that time.

In the tables presented the filter names has been shortened to \emph{Pred} and \emph{Temp}. \emph{Pred} means the predecessor filter and \emph{Temp} means the temporal filter. We will also use two additional notations in the rime rows; "-" and "!". "-" means that the run did not complete within the given time frame. "!" means that the solver raised an error when reading the FlatZinc file.

The runtime will be presented in two formats, milliseconds and \emph{hours:minutes:seconds}, in the latter the remaining milliseconds are omitted.


\input{Tables/results_g12}

\input{Tables/results_jacop}

\input{Tables/results_cpx}

\input{Tables/results_gecode}

\input{Tables/results_or}

\input{Tables/results_choco}

If one just does a quick comparison of the numbers in the tables without doing any deeper analysis, one can see that the results from Gecode, or-tools and Choco3, shown in tables \ref{tab:res_gecode}, \ref{tab:res_or} and \ref{tab:res_choco}, respectively, are identical. This hints that the FlatZinc files for these solvers should be very similar. And indeed, if one compares the FlatZinc files for these three solvers for one of the cases, they are as good as identical. The difference between them is the naming of some constraints and sometimes the placement in the file.

As can be seen in the times or the runs, not many of the runs completed in time. Only 9 runs completed by 3 solvers. Interesting to note is the very varying runtimes. It ranges from 60 milliseconds to 16 minutes. Almost no solver could solve the problem using MiniZinc 2.0.1, two of them threw errors reading the FlatZinc file, despite its claimed backwards compatibility, and most others took too long time solving it. But, interestingly Gecode manages to solve the problem using 2.0.1, even faster than using 1.6, and even being the fastest to solve the problem of all the runs in just 60 milliseconds.
\\\\
By our definition of a result, these are the runs that found the optimal solution and ended the search by concluding that the optimal solution was found. This means that there are other runs that still produced results, sometimes even the optimal one, but did not end the search in time and therefore not qualify as a result.

The G12/FD runs using predecessor and temporal filter with version 2.0.1, using predecessor filter with version 1.6 and using predecessor filter with version 2.0.1 all find solutions, although none of them are the optimal.

The JaCoP runs using predecessor and temporal filter with version 2.0.1 and using predecessor filter with version 2.0.1 both finds all the solutions, including the optimal solution, immediately. This is also the case for JaCoP using predecessor filter with version 1.6.

The Gecode run using predecessor filter with version 2.0.1 finds three solution immediately of which one is the optimal. Interestingly, the run using no filter also with version 2.0.1 finds only one solution and that one is the optimal in roughly the same time.

The Choco3 runs using the predecessor and temporal filters and the ones using predecessor filter, independent of version, all finds two solutions immediately.

We should mention that some of the tests ran for much longer than the time limit set at 4 hours. And although not all produced results even when left for more than 4 hours, some managed to produce results. One that could be mentioned is Opturion CPX that in some cases took around 6 hours to complete.

We should also mention that Opturion CPX has the option to use the search strategy "warm start". This was tested but, as with regular complete search, did not produce a result within the time frame and thus we have not specifically included the results here.
\\\\
We will present some more tables that show the change in the values. The first 4 columns are grouped by the version of MiniZinc and in each of those groups we show the change in the values if each of the filters are added. The last column shows the change in values if going from using the 1.6 version to using the 2.0.1 version. The values presented are averages. For example, the change for when adding the temporal filter for version 1.6 is the average of the changes from not using any filters to using the temporal filter and from using the predecessor filter to using the temporal and predecessor filters. The average for the last column is just the average of the changes for all cases when switching from 1.6 to 2.0.1.

As mentioned before, the results for Gecode, or-tools and Choco3 are identical, and thus we grouped them together into one table below.

\input{Tables/results_diff_g12}

\input{Tables/results_diff_jacop}

\input{Tables/results_diff_cpx}

\input{Tables/results_diff_gecode_or_choco}
\newpage
When we look at the change in values for the filters we see that the predecessor filter for G12/FD using version 1.6 increases the number of variables, both integer and boolean, as opposed to the other solvers which does not change the number of variables at all. Except for Opturion CPX, which adds a very small amount of variables. When using G12/FD with 2.0.1 the predecessor filter increases the number of integer variables as well, as opposed to the other solvers decreasing the number of integer variables. Again except Optuion CPX who increases the number a very small amount.

Both the predecessor filter and temporal filter increases the number of constraints significantly, except for Opturion CPX where the change is not that great. And the largest increase is for the temporal constraint, which lies around 200\% for all the solvers. This can be compared to using 2.0.1, where the change is 0\%. The same can be observed for the predecessor filter, but here we still have a small change in the number of constraints, but not as large as with 1.6. The temporal filter also decreases the number of variables in 2.0.1, as opposed to 1.6 where it did not change that number at all. When using the temporal filter with Opturion CPX with 2.0.1, the filter helps to reduce all the values, and quite dramatically so, all except reified lies around 67\%.
\\\\
Compared to 1.6, 2.0.1 seems to increase the number of integer variables by a lot, around 50\%. And once again except for Opturion CPX where it decreases by around 30\%. The same goes for boolean variables, but in the other direction. For all solvers, including Opturion CPX, the number of boolean variables decreases by around 33\%. The number of arrays also increases for all the solvers, especially for Opturion CPX, where the increase is a staggering almost 32000\%. 2.0.1 also decreases the number of constraints by about 48\% on average for all the solvers. But despite removing constraints, the amount of reified constraints increases by about 40\%, except for Opturion CPX where the change is only 0.2\%.
\\\\
Unfortunately no solver was able to run both the 1.6 version and the 2.0.1 version. Therefore we cannot make a good comparison and make a definitive statement about which version is the most effective. Although, the 2.0.1 version shows promising results for Gecode.
\\\\
\begin{figure}[h]
\centering
\input{Plots/int_vs_time}
\caption{\# integer variables vs time}
\label{fig:int_vs_time}
\end{figure}

\begin{figure}[h]
\centering
\input{Plots/bool_vs_time}
\caption{\# boolean variables vs time}
\label{fig:bool_vs_time}
\end{figure}

\begin{figure}[h]
\centering
\input{Plots/tot_vs_time}
\caption{Total \# of variables vs time}
\label{fig:tot_vs_time}
\end{figure}

\begin{figure}[h]
\centering
\input{Plots/arr_vs_time}
\caption{\# arrays vs time}
\label{fig:arr_vs_time}
\end{figure}

\begin{figure}[h]
\centering
\input{Plots/const_vs_time}
\caption{\# constraints vs time}
\label{fig:const_vs_time}
\end{figure}

\begin{figure}[h]
\centering
\input{Plots/reif_vs_time}
\caption{\% reified vs time}
\label{fig:reif_vs_time}
\end{figure}

\noindent In Figures \ref{fig:int_vs_time}, \ref{fig:bool_vs_time}, \ref{fig:tot_vs_time}, \ref{fig:arr_vs_time}, \ref{fig:const_vs_time} and \ref{fig:reif_vs_time} we plot the values taken from tables \ref{tab:res_g12}, \ref{tab:res_jacop}, \ref{tab:res_cpx}, \ref{tab:res_gecode}, \ref{tab:res_or} and \ref{tab:res_choco} versus time. The time is on the y-axis and is logarithmic.

As can be seen in Figures \ref{fig:int_vs_time}, \ref{fig:bool_vs_time}, \ref{fig:tot_vs_time}, \ref{fig:arr_vs_time}, \ref{fig:const_vs_time} and \ref{fig:reif_vs_time}, we cannot conclude any relation between the time for the solution and the number of either integer, booleans, arrays, constraints or the percentage of reified constraints. This can also be seen if we study the results for Gecode, or-tools and Choco3. Since they get the same values for the FlatZinc files but completely different times, we can conclude that our data does not show any relation between time and those values.
\\\\
We should also mention that we tried to run all the solvers using a very small assembly, basically one with a pick up and a put down of a component. All solvers solved it in essentially no time, except Opturion CPX, which could not solve it at all, even after 50 minutes.